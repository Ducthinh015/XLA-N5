"""
Script ph√°t hi·ªán bi·ªÉn b√°o tr√™n video
"""
import os
import cv2
from ultralytics import YOLO
from pathlib import Path
from config import (
    get_model_path,
    CONFIDENCE_THRESHOLD,
    OUTPUT_DIR,
    print_config
)

class VideoDetector:
    def __init__(self, model_path=None):
        """Kh·ªüi t·∫°o detector v·ªõi model YOLO"""
        if model_path is None:
            model_path = get_model_path("trained")
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y model t·∫°i {model_path}")
        
        self.model = YOLO(model_path)
        print(f"‚úÖ ƒê√£ t·∫£i model: {model_path}")
    
    def detect_video(self, video_path, output_path=None, save_annotated=True):
        """
        Ph√°t hi·ªán bi·ªÉn b√°o tr√™n video
        
        Args:
            video_path: ƒê∆∞·ªùng d·∫´n video input
            output_path: ƒê∆∞·ªùng d·∫´n video output (n·∫øu None s·∫Ω t·ª± t·∫°o)
            save_annotated: C√≥ l∆∞u video ƒë√£ ƒë∆∞·ª£c annotate kh√¥ng
        
        Returns:
            dict: Th√¥ng tin c√°c ph√°t hi·ªán
        """
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y video t·∫°i {video_path}")
        
        print(f"\nüé• ƒêang x·ª≠ l√Ω video: {os.path.basename(video_path)}")
        
        # T·∫°o output path n·∫øu ch∆∞a c√≥
        if output_path is None:
            os.makedirs(OUTPUT_DIR, exist_ok=True)
            video_name = Path(video_path).stem
            output_path = os.path.join(OUTPUT_DIR, f"{video_name}_detected.mp4")
        
        # Detect v·ªõi YOLO
        # results l√† list c·ªßa t·ª´ng frame
        results = self.model.predict(
            source=video_path,
            conf=CONFIDENCE_THRESHOLD,
            save=save_annotated,
            project=OUTPUT_DIR,
            name="video_detections",
            verbose=True
        )
        
        # L∆∞u video ƒë√£ x·ª≠ l√Ω
        if save_annotated:
            # YOLO t·ª± ƒë·ªông l∆∞u video trong runs/detect/video_detections/
            print(f"‚úÖ Video ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_path}")
        
        # Th·ªëng k√™
        total_detections = 0
        class_counts = {}
        
        for frame_result in results:
            if frame_result.boxes is not None:
                for box in frame_result.boxes:
                    total_detections += 1
                    cls_id = int(box.cls[0])
                    cls_name = self.model.names[cls_id]
                    class_counts[cls_name] = class_counts.get(cls_name, 0) + 1
        
        # In th·ªëng k√™
        print("\n" + "="*50)
        print("üìä TH·ªêNG K√ä PH√ÅT HI·ªÜN")
        print("="*50)
        print(f"T·ªïng s·ªë bi·ªÉn b√°o ph√°t hi·ªán ƒë∆∞·ª£c: {total_detections}")
        print(f"\nChi ti·∫øt theo lo·∫°i:")
        for cls_name, count in sorted(class_counts.items(), key=lambda x: -x[1]):
            print(f"  - {cls_name}: {count}")
        print("="*50)
        
        return {
            "total_detections": total_detections,
            "class_counts": class_counts,
            "output_path": output_path,
            "frames": len(results)
        }
    
    def detect_webcam(self):
        """Ph√°t hi·ªán real-time t·ª´ webcam"""
        print("\nüìπ B·∫Øt ƒë·∫ßu ph√°t hi·ªán t·ª´ webcam...")
        print("Nh·∫•n 'q' ƒë·ªÉ tho√°t")
        
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            raise RuntimeError("Kh√¥ng th·ªÉ m·ªü webcam")
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Detect
                results = self.model.predict(
                    source=frame,
                    conf=CONFIDENCE_THRESHOLD,
                    verbose=False
                )
                
                # V·∫Ω k·∫øt qu·∫£
                annotated_frame = results[0].plot()
                cv2.imshow("Nh·∫≠n di·ªán bi·ªÉn b√°o", annotated_frame)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
        finally:
            cap.release()
            cv2.destroyAllWindows()
            print("‚úÖ ƒê√£ d·ª´ng webcam")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Ph√°t hi·ªán bi·ªÉn b√°o giao th√¥ng tr√™n video"
    )
    parser.add_argument(
        "--video",
        type=str,
        help="ƒê∆∞·ªùng d·∫´n video file"
    )
    parser.add_argument(
        "--webcam",
        action="store_true",
        help="S·ª≠ d·ª•ng webcam real-time"
    )
    parser.add_argument(
        "--model",
        type=str,
        default=MODEL_PATH,
        help="ƒê∆∞·ªùng d·∫´n model (.pt file)"
    )
    parser.add_argument(
        "--conf",
        type=float,
        default=CONFIDENCE_THRESHOLD,
        help="Ng∆∞·ª°ng confidence (default: 0.3)"
    )
    parser.add_argument(
        "--output",
        type=str,
        help="ƒê∆∞·ªùng d·∫´n video output"
    )
    parser.add_argument(
        "--config",
        action="store_true",
        help="In c·∫•u h√¨nh v√† tho√°t"
    )
    
    args = parser.parse_args()
    
    # In c·∫•u h√¨nh
    if args.config:
        print_config()
        return
    
    # Kh·ªüi t·∫°o detector
    detector = VideoDetector(args.model)
    
    if args.webcam:
        # Ph√°t hi·ªán webcam
        detector.detect_webcam()
    elif args.video:
        # Ph√°t hi·ªán video file
        detector.detect_video(args.video, args.output)
    else:
        print("‚ùå Vui l√≤ng ch·ªçn --video ho·∫∑c --webcam")
        parser.print_help()

if __name__ == "__main__":
    main()

